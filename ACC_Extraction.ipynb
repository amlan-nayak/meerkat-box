{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For different groups change the text between /Raw Data and /Collar in MainPath and /Processed Data and /ACC in SavePath\n",
    "#Different Groups -  ZU_2021_1, ZU_2021_2, NQ_2021_1 and RW_2021_1\n",
    "\n",
    "MainPath = '/media/amlan/Data/Thesis Data/Raw Data/ZU_2021_1/COLLAR/GPS/'\n",
    "SavePath = '/media/amlan/Data/Thesis Data/Processed Data/ZU_2021_1/ACC/'\n",
    "\n",
    "os.makedirs(SavePath, exist_ok=True)\n",
    "\n",
    "paths = os.listdir(MainPath)\n",
    "paths = [i for i in paths if 'DS_Store' not in i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZU_VZUF051_RRTB_Axy010_20210516-20210524', 'ZU_VZUF052_RRRT_Axy018_20210516-20210524', 'ZU_VZUF054_RRRS_Axy003_20210515-20210516', 'ZU_VZUF054_RRRS_Axy019_20210517-20210524', 'ZU_VZUM053_RRLT_Axy001_20210518-20210524', 'ZU_VZUM056_LTRT_Axy004_20210516-20210518', 'ZU_VZUM057_LTTB_Axy015_20210519-20210524', 'ZU_VZUM057_LTTB_Axy019_20210516-20210516', 'ZU_VZUM059_LTLS_Axy011_20210516-20210523']\n"
     ]
    }
   ],
   "source": [
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "File: ZU_VZUF051_RRTB_Axy010_20210516-20210524 with Dimensions (8403291, 4)\n",
      "Data in the file:\n",
      "                 Timestamp      X      Y      Z\n",
      "0  14/05/2021 16:15:24.000 -1.000 -0.438 -0.125\n",
      "1  14/05/2021 16:15:24.100 -0.888 -0.550 -0.013\n",
      "2  14/05/2021 16:15:24.200 -0.925 -0.563  0.000\n",
      "\n",
      "Data After Cleaning Leading Zeros:\n",
      "                 Timestamp      X      Y      Z\n",
      "0  14/05/2021 16:15:24.000 -1.000 -0.438 -0.125\n",
      "1  14/05/2021 16:15:24.100 -0.888 -0.550 -0.013\n",
      "2  14/05/2021 16:15:24.200 -0.925 -0.563  0.000\n",
      "Dimensions after removing leading empty rows:  (8403291, 4)\n",
      "\n",
      "Unique Times:  840329\n",
      "Dimension of ACC Values After Considering Unique Times:  (8403290, 3)\n",
      "--------------------------------------------------\n",
      "\n",
      "File: ZU_VZUF052_RRRT_Axy018_20210516-20210524 with Dimensions (7790771, 4)\n",
      "Data in the file:\n",
      "                 Timestamp    X    Y    Z\n",
      "0  12/05/2021 14:20:20.000  0.0  0.0  0.0\n",
      "1  12/05/2021 14:20:49.000  0.0  0.0  0.0\n",
      "2  12/05/2021 14:21:19.000  0.0  0.0  0.0\n",
      "There are leading zeros till  8640\n",
      "\n",
      "Data After Cleaning Leading Zeros:\n",
      "                    Timestamp      X      Y      Z\n",
      "8640  15/05/2021 14:20:19.000  0.000 -0.938  0.063\n",
      "8641  15/05/2021 14:20:19.100  0.050 -0.988  0.013\n",
      "8642  15/05/2021 14:20:19.200  0.063 -0.963 -0.038\n",
      "Dimensions after removing leading empty rows:  (7782131, 4)\n",
      "\n",
      "Unique Times:  778213\n",
      "Dimension of ACC Values After Considering Unique Times:  (7782130, 3)\n",
      "--------------------------------------------------\n",
      "\n",
      "File: ZU_VZUF054_RRRS_Axy003_20210515-20210516 with Dimensions (1620101, 4)\n",
      "Data in the file:\n",
      "                 Timestamp      X      Y      Z\n",
      "0  14/05/2021 17:48:34.000 -0.938 -0.375 -0.313\n",
      "1  14/05/2021 17:48:34.100 -0.938 -0.375 -0.313\n",
      "2  14/05/2021 17:48:34.200 -0.938 -0.313 -0.313\n",
      "\n",
      "Data After Cleaning Leading Zeros:\n",
      "                 Timestamp      X      Y      Z\n",
      "0  14/05/2021 17:48:34.000 -0.938 -0.375 -0.313\n",
      "1  14/05/2021 17:48:34.100 -0.938 -0.375 -0.313\n",
      "2  14/05/2021 17:48:34.200 -0.938 -0.313 -0.313\n",
      "Dimensions after removing leading empty rows:  (1620101, 4)\n",
      "\n",
      "Unique Times:  162010\n",
      "Dimension of ACC Values After Considering Unique Times:  (1620100, 3)\n",
      "--------------------------------------------------\n",
      "\n",
      "File: ZU_VZUF054_RRRS_Axy019_20210517-20210524 with Dimensions (7770010, 4)\n",
      "Data in the file:\n",
      "                 Timestamp    X    Y    Z\n",
      "0  12/05/2021 14:20:18.000  0.0  0.0  0.0\n",
      "1  12/05/2021 14:20:47.000  0.0  0.0  0.0\n",
      "2  12/05/2021 14:21:17.000  0.0  0.0  0.0\n",
      "There are leading zeros till  8640\n",
      "\n",
      "Data After Cleaning Leading Zeros:\n",
      "                    Timestamp      X      Y      Z\n",
      "8640  15/05/2021 14:20:17.000 -1.063 -0.313  0.563\n",
      "8641  15/05/2021 14:20:17.100 -0.913 -0.113  0.513\n",
      "8642  15/05/2021 14:20:17.200 -0.950 -0.250  0.238\n",
      "Dimensions after removing leading empty rows:  (7761370, 4)\n",
      "\n",
      "Unique Times:  776137\n",
      "Dimension of ACC Values After Considering Unique Times:  (7761370, 3)\n",
      "--------------------------------------------------\n",
      "\n",
      "File: ZU_VZUM053_RRLT_Axy001_20210518-20210524 with Dimensions (5547431, 4)\n",
      "Data in the file:\n",
      "                 Timestamp    X    Y    Z\n",
      "0  15/05/2021 04:55:01.000  0.0  0.0  0.0\n",
      "1  15/05/2021 04:55:30.000  0.0  0.0  0.0\n",
      "2  15/05/2021 04:56:00.000  0.0  0.0  0.0\n",
      "There are leading zeros till  8640\n",
      "\n",
      "Data After Cleaning Leading Zeros:\n",
      "                    Timestamp      X      Y      Z\n",
      "8640  18/05/2021 04:55:00.000 -0.250 -0.938  0.125\n",
      "8641  18/05/2021 04:55:00.100 -0.150 -0.938  0.225\n",
      "8642  18/05/2021 04:55:00.200 -0.163 -0.938  0.175\n",
      "Dimensions after removing leading empty rows:  (5538791, 4)\n",
      "\n",
      "Unique Times:  553879\n",
      "Dimension of ACC Values After Considering Unique Times:  (5538790, 3)\n",
      "--------------------------------------------------\n",
      "\n",
      "File: ZU_VZUM056_LTRT_Axy004_20210516-20210518 with Dimensions (2397050, 4)\n",
      "Data in the file:\n",
      "                 Timestamp      X      Y      Z\n",
      "0  15/05/2021 13:53:34.000  0.688 -0.625 -0.438\n",
      "1  15/05/2021 13:53:34.100  0.625 -0.563 -0.438\n",
      "2  15/05/2021 13:53:34.200  0.625 -0.625 -0.438\n",
      "\n",
      "Data After Cleaning Leading Zeros:\n",
      "                 Timestamp      X      Y      Z\n",
      "0  15/05/2021 13:53:34.000  0.688 -0.625 -0.438\n",
      "1  15/05/2021 13:53:34.100  0.625 -0.563 -0.438\n",
      "2  15/05/2021 13:53:34.200  0.625 -0.625 -0.438\n",
      "Dimensions after removing leading empty rows:  (2397050, 4)\n",
      "\n",
      "Unique Times:  239705\n",
      "Dimension of ACC Values After Considering Unique Times:  (2397050, 3)\n",
      "--------------------------------------------------\n",
      "\n",
      "File: ZU_VZUM057_LTTB_Axy015_20210519-20210524 with Dimensions (4648181, 4)\n",
      "Data in the file:\n",
      "                 Timestamp    X    Y    Z\n",
      "0  16/05/2021 06:22:23.000  0.0  0.0  0.0\n",
      "1  16/05/2021 06:22:52.000  0.0  0.0  0.0\n",
      "2  16/05/2021 06:23:22.000  0.0  0.0  0.0\n",
      "There are leading zeros till  8640\n",
      "\n",
      "Data After Cleaning Leading Zeros:\n",
      "                    Timestamp      X      Y      Z\n",
      "8640  19/05/2021 06:22:22.000 -1.063 -0.188  0.250\n",
      "8641  19/05/2021 06:22:22.100 -0.913 -0.188  0.200\n",
      "8642  19/05/2021 06:22:22.200 -0.913 -0.188  0.188\n",
      "Dimensions after removing leading empty rows:  (4639541, 4)\n",
      "\n",
      "Unique Times:  463954\n",
      "Dimension of ACC Values After Considering Unique Times:  (4639540, 3)\n",
      "--------------------------------------------------\n",
      "\n",
      "File: ZU_VZUM057_LTTB_Axy019_20210516-20210516 with Dimensions (7770010, 4)\n",
      "Data in the file:\n",
      "                 Timestamp    X    Y    Z\n",
      "0  12/05/2021 14:20:18.000  0.0  0.0  0.0\n",
      "1  12/05/2021 14:20:47.000  0.0  0.0  0.0\n",
      "2  12/05/2021 14:21:17.000  0.0  0.0  0.0\n",
      "There are leading zeros till  8640\n",
      "\n",
      "Data After Cleaning Leading Zeros:\n",
      "                    Timestamp      X      Y      Z\n",
      "8640  15/05/2021 14:20:17.000 -1.063 -0.313  0.563\n",
      "8641  15/05/2021 14:20:17.100 -0.913 -0.113  0.513\n",
      "8642  15/05/2021 14:20:17.200 -0.950 -0.250  0.238\n",
      "Dimensions after removing leading empty rows:  (7761370, 4)\n",
      "\n",
      "Unique Times:  776137\n",
      "Dimension of ACC Values After Considering Unique Times:  (7761370, 3)\n",
      "--------------------------------------------------\n",
      "\n",
      "File: ZU_VZUM059_LTLS_Axy011_20210516-20210523 with Dimensions (6719091, 4)\n",
      "Data in the file:\n",
      "                 Timestamp      X      Y      Z\n",
      "0  15/05/2021 13:27:19.000  0.313  0.063  0.938\n",
      "1  15/05/2021 13:27:19.100  0.256  0.006  0.938\n",
      "2  15/05/2021 13:27:19.200  0.800 -0.200  0.638\n",
      "\n",
      "Data After Cleaning Leading Zeros:\n",
      "                 Timestamp      X      Y      Z\n",
      "0  15/05/2021 13:27:19.000  0.313  0.063  0.938\n",
      "1  15/05/2021 13:27:19.100  0.256  0.006  0.938\n",
      "2  15/05/2021 13:27:19.200  0.800 -0.200  0.638\n",
      "Dimensions after removing leading empty rows:  (6719091, 4)\n",
      "\n",
      "Unique Times:  671909\n",
      "Dimension of ACC Values After Considering Unique Times:  (6719090, 3)\n"
     ]
    }
   ],
   "source": [
    "freq=10 #Enter the known fequency for the particular group. NQ1 and ZU2 are 50 Hz, RW and ZU1 are 10 Hz.\n",
    "\n",
    "def clean_leading_zeros(df):\n",
    "    \n",
    "    if pd.to_datetime(df.loc[1,'Timestamp']) - pd.to_datetime(df.loc[0,'Timestamp']) >= pd.Timedelta(1, \"s\") :\n",
    "        Leading_Zeros = df.loc[~(df.drop(['Timestamp'],axis=1)==0).all(axis=1)]\n",
    "        if Leading_Zeros.empty:\n",
    "            return Leading_Zeros\n",
    "        else:\n",
    "            print('There are leading zeros till ',Leading_Zeros.index[0])\n",
    "            return df.loc[Leading_Zeros.index[0]::,:]\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def load_ACC_files(x,MainPath):\n",
    "    #File = 'NQ_VNQF014_SHLT_Axy_002_20210811-20210817/NQ_VNQF014_SHLT_Axy_002_20210811-20210817.csv'\n",
    "    \n",
    "    File = str(x) + '/' + str(x) + '.csv' \n",
    "    Data = pd.read_csv(MainPath + File,usecols = ['Timestamp','X','Y','Z'])\n",
    "    print('--------------------------------------------------')\n",
    "    print('\\nFile: {} with Dimensions {}'.format(x,Data.shape))\n",
    "    print('Data in the file:')\n",
    "    print(Data.head(3))\n",
    "    \n",
    "    Data = clean_leading_zeros(Data)\n",
    "    print('\\nData After Cleaning Leading Zeros:')\n",
    "    print(Data.head(3)) \n",
    "    \n",
    "    print('Dimensions after removing leading empty rows: ',Data.shape)\n",
    "    Data = Data.reset_index(drop=True)\n",
    "          \n",
    "    return Data    \n",
    "    \n",
    "def feature_extraction_ACC(Values,Unique_Time,freq):\n",
    "    \n",
    "    Norm = np.sqrt(np.sum(np.square(Values),axis=1))\n",
    "    t = pd.to_datetime(Data.loc[0:Unique_Time*freq-1:freq,'Timestamp'],format=\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "    vedba = np.std(Norm.reshape(Unique_Time,freq),axis=1)\n",
    "    means = np.mean(Values.reshape((Unique_Time,freq,3)),axis=1)\n",
    "    maxes = np.max(Values.reshape((Unique_Time,freq,3)),axis=1)\n",
    "    mins = np.min(Values.reshape((Unique_Time,freq,3)),axis=1)\n",
    "    std = np.std(Values.reshape((Unique_Time,freq,3)),axis=1)\n",
    "    \n",
    "    return t,vedba,means,std,maxes,mins\n",
    "\n",
    "\n",
    "    \n",
    "for y in paths:\n",
    "    \n",
    "    \n",
    "    Data = load_ACC_files(y,MainPath)\n",
    "\n",
    "\n",
    "    Unique_Time= Data.shape[0]//freq\n",
    "    print('\\nUnique Times: ',Unique_Time)\n",
    "\n",
    "\n",
    "    Values = Data.iloc[0:Unique_Time*freq,1:4].to_numpy()\n",
    "    print('Dimension of ACC Values After Considering Unique Times: ',Values.shape)\n",
    "    \n",
    "    t,vedba,means,std,maxes,mins = feature_extraction_ACC(Values,Unique_Time,freq)\n",
    "\n",
    "\n",
    "    Features_Data = pd.DataFrame(columns=['Timestamp','X_Mean','Y_Mean','Z_Mean','X_Std','Y_Std','Z_Std','X_Max','Y_Max','Z_Max','X_Min','Y_Min','Z_Min','VeDBA'])\n",
    "    Features_Data['Timestamp'] = t\n",
    "    Features_Data['VeDBA'] = vedba\n",
    "    Features_Data.iloc[:,1:4] = means\n",
    "    Features_Data.iloc[:,4:7] = std\n",
    "    Features_Data.iloc[:,7:10] = maxes\n",
    "    Features_Data.iloc[:,10:13] = mins\n",
    "    \n",
    "    Features_Data = Features_Data.reset_index(drop=True)\n",
    "    \n",
    "    Features_Data.to_csv(SavePath + y +'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18/02/2020 16:02:01.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/02/2020 16:02:30.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18/02/2020 16:03:00.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18/02/2020 16:03:30.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18/02/2020 16:04:00.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>18/02/2020 19:52:30.900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>18/02/2020 19:52:30.920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>18/02/2020 19:52:30.940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>18/02/2020 19:52:30.960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>18/02/2020 19:52:30.980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Timestamp    X    Y    Z\n",
       "0    18/02/2020 16:02:01.000  0.0  0.0  0.0\n",
       "1    18/02/2020 16:02:30.000  0.0  0.0  0.0\n",
       "2    18/02/2020 16:03:00.000  0.0  0.0  0.0\n",
       "3    18/02/2020 16:03:30.000  0.0  0.0  0.0\n",
       "4    18/02/2020 16:04:00.000  0.0  0.0  0.0\n",
       "..                       ...  ...  ...  ...\n",
       "506  18/02/2020 19:52:30.900  0.0  0.0  0.0\n",
       "507  18/02/2020 19:52:30.920  0.0  0.0  0.0\n",
       "508  18/02/2020 19:52:30.940  0.0  0.0  0.0\n",
       "509  18/02/2020 19:52:30.960  0.0  0.0  0.0\n",
       "510  18/02/2020 19:52:30.980  0.0  0.0  0.0\n",
       "\n",
       "[511 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Timestamp, X, Y, Z]\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Data\n",
    "df.loc[~(df.drop(['Timestamp'],axis=1)==0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18440"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Features_Data['VeDBA'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig.savefig('ZU1_2021.png',dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File:  ZU_VZUF052_RRRT_Axy018_20210516-20210524\n",
      "Dimensions:  (7790771, 4)\n",
      "                 Timestamp    X    Y    Z\n",
      "0  12/05/2021 14:20:20.000  0.0  0.0  0.0\n",
      "1  12/05/2021 14:20:49.000  0.0  0.0  0.0\n",
      "2  12/05/2021 14:21:19.000  0.0  0.0  0.0\n",
      "There are leading zeros till  8640\n",
      "                    Timestamp      X      Y      Z\n",
      "8640  15/05/2021 14:20:19.000  0.000 -0.938  0.063\n",
      "8641  15/05/2021 14:20:19.100  0.050 -0.988  0.013\n",
      "8642  15/05/2021 14:20:19.200  0.063 -0.963 -0.038\n",
      "Dimensions after removing leading empty rows:  (7782131, 4)\n",
      "Unique Times:  778213\n",
      "Dimension After Considering Unique Times:  (7782130, 3)\n"
     ]
    }
   ],
   "source": [
    "def clean_leading_zeros(df):\n",
    "    \n",
    "    if pd.to_datetime(df.loc[1,'Timestamp']) - pd.to_datetime(df.loc[0,'Timestamp']) >= pd.Timedelta(1, \"s\") :\n",
    "        Leading_Zeros = df.loc[~(df.drop(['Timestamp'],axis=1)==0).all(axis=1)].index[0]\n",
    "        print('There are leading zeros till ',Leading_Zeros)\n",
    "        return df.loc[Leading_Zeros::,:]\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "y = paths[1]\n",
    "freq = 10\n",
    "File = str(y) + '/' + str(y) + '.csv' \n",
    "Data = pd.read_csv(MainPath + File,usecols = ['Timestamp','X','Y','Z']) \n",
    "print('\\nFile: ', y)\n",
    "print('Dimensions: ',Data.shape)\n",
    "print(Data.head(3))\n",
    "\n",
    "Data = clean_leading_zeros(Data)\n",
    "print(Data.head(3))\n",
    "\n",
    "\n",
    "print('Dimensions after removing leading empty rows: ',Data.shape)\n",
    "#print(Data.reset_index(drop=True).head())\n",
    "Data = Data.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "Unique_Time= Data.shape[0]//freq\n",
    "print('Unique Times: ',Unique_Time)\n",
    "\n",
    "\n",
    "Values = Data.iloc[0:Unique_Time*freq,1:4].to_numpy()\n",
    "print('Dimension After Considering Unique Times: ',Values.shape)\n",
    "\n",
    "Norm = np.sqrt(np.sum(np.square(Values),axis=1))\n",
    "Features_Data = pd.DataFrame(columns=['Timestamp','X_Mean','Y_Mean','Z_Mean','X_Max','Y_Max','Z_Max','X_Min','Y_Min','Z_Min','VeDBA'])\n",
    "t,vedba,means, = [],[],[]\n",
    "    #x_max,x_min,y_max,y_min,z_max,z_min = [],[],[],[],[],[]\n",
    "#for i in range(Unique_Time):\n",
    "#        t.append(pd.to_datetime(Data.loc[freq*i,'Timestamp'],format=\"%d/%m/%Y %H:%M:%S.%f\"))\n",
    " #       vedba.append(np.std(Norm[freq*i:freq*(i+1)]))\n",
    " #       means.append(np.mean(Values[freq*i:freq*(i+1),:],axis=0))\n",
    "        #maxes = np.max(Values[freq*i:freq*(i+1),:],axis=0)\n",
    "        #mins = np.min(Values[freq*i:freq*(i+1),:],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slower Looping Version using lists \n",
    "t,vedba,means, = [],[],[]\n",
    "Maxes,Mins = [],[]\n",
    "for i in range(Unique_Time):\n",
    "        t.append(pd.to_datetime(Data.loc[freq*i,'Timestamp'],format=\"%d/%m/%Y %H:%M:%S.%f\"))\n",
    "        vedba.append(np.std(Norm[freq*i:freq*(i+1)]))\n",
    "        means.append(np.mean(Values[freq*i:freq*(i+1),:],axis=0))\n",
    "        Maxes.append(np.max(Values[freq*i:freq*(i+1),:],axis=0))\n",
    "        Mins.append(np.min(Values[freq*i:freq*(i+1),:],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Timestamp('2021-05-15 14:20:19'),\n",
       "  Timestamp('2021-05-15 14:20:20'),\n",
       "  Timestamp('2021-05-15 14:20:21'),\n",
       "  Timestamp('2021-05-15 14:20:22'),\n",
       "  Timestamp('2021-05-15 14:20:23')],\n",
       " [Timestamp('2021-05-24 14:30:22'),\n",
       "  Timestamp('2021-05-24 14:30:23'),\n",
       "  Timestamp('2021-05-24 14:30:24'),\n",
       "  Timestamp('2021-05-24 14:30:25'),\n",
       "  Timestamp('2021-05-24 14:30:26'),\n",
       "  Timestamp('2021-05-24 14:30:27'),\n",
       "  Timestamp('2021-05-24 14:30:28'),\n",
       "  Timestamp('2021-05-24 14:30:29'),\n",
       "  Timestamp('2021-05-24 14:30:30'),\n",
       "  Timestamp('2021-05-24 14:30:31')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0:5],t[-10::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    2021-05-15 14:20:19\n",
       " 10   2021-05-15 14:20:20\n",
       " 20   2021-05-15 14:20:21\n",
       " 30   2021-05-15 14:20:22\n",
       " 40   2021-05-15 14:20:23\n",
       " Name: Timestamp, dtype: datetime64[ns],\n",
       " 7782030   2021-05-24 14:30:22\n",
       " 7782040   2021-05-24 14:30:23\n",
       " 7782050   2021-05-24 14:30:24\n",
       " 7782060   2021-05-24 14:30:25\n",
       " 7782070   2021-05-24 14:30:26\n",
       " 7782080   2021-05-24 14:30:27\n",
       " 7782090   2021-05-24 14:30:28\n",
       " 7782100   2021-05-24 14:30:29\n",
       " 7782110   2021-05-24 14:30:30\n",
       " 7782120   2021-05-24 14:30:31\n",
       " Name: Timestamp, dtype: datetime64[ns])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T= pd.to_datetime(Data.loc[0:Unique_Time*freq-1:freq,'Timestamp'],format=\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "T[0:5],T[-10::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.14731904623265418,\n",
       "  0.18768463229058646,\n",
       "  0.18435571156795733,\n",
       "  0.2286249352913698,\n",
       "  0.16249118130245607],\n",
       " [0.04776558218394699,\n",
       "  0.023159757320851744,\n",
       "  0.008269332792060735,\n",
       "  0.0180106010264387,\n",
       "  0.021037291735867998])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vedba[0:5], vedba[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.14731905, 0.18768463, 0.18435571, 0.22862494, 0.16249118]),\n",
       " array([0.04776558, 0.02315976, 0.00826933, 0.0180106 , 0.02103729]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = Norm.reshape((Unique_Time,freq)).std(axis=1)\n",
    "\n",
    "V[0:5], V[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([-0.0176, -1.0291,  0.1439]),\n",
       "  array([ 0.0064, -1.0003,  0.2003]),\n",
       "  array([-0.1689, -0.8189,  0.419 ]),\n",
       "  array([ 0.0752, -1.0189,  0.1315]),\n",
       "  array([-0.0252, -1.0066,  0.1628])],\n",
       " [array([ 0.4192, -0.0754,  0.8066]),\n",
       "  array([ 0.3504, -0.0692,  0.8751]),\n",
       "  array([ 0.4317, -0.0441,  0.813 ]),\n",
       "  array([ 0.3565, -0.0629,  0.8813]),\n",
       "  array([ 0.4254, -0.0063,  0.8254])])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means[0:5], means[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.0176, -1.0291,  0.1439],\n",
       "        [ 0.0064, -1.0003,  0.2003],\n",
       "        [-0.1689, -0.8189,  0.419 ],\n",
       "        [ 0.0752, -1.0189,  0.1315],\n",
       "        [-0.0252, -1.0066,  0.1628]]),\n",
       " array([[ 0.4192, -0.0754,  0.8066],\n",
       "        [ 0.3504, -0.0692,  0.8751],\n",
       "        [ 0.4317, -0.0441,  0.813 ],\n",
       "        [ 0.3565, -0.0629,  0.8813],\n",
       "        [ 0.4254, -0.0063,  0.8254]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M= Values.reshape((Unique_Time,freq,3)).mean(axis=1)\n",
    "M[0:5], M[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([ 0.063, -0.938,  0.45 ]),\n",
       "  array([ 0.25 , -0.813,  0.563]),\n",
       "  array([ 0.188, -0.375,  0.875]),\n",
       "  array([ 0.25 , -0.75 ,  0.375]),\n",
       "  array([ 0.125, -0.875,  0.563])],\n",
       " [array([ 0.438, -0.063,  0.875]),\n",
       "  array([ 0.438, -0.063,  0.938]),\n",
       "  array([0.438, 0.   , 0.813]),\n",
       "  array([0.438, 0.   , 0.938]),\n",
       "  array([0.438, 0.   , 0.875])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Maxes[0:5],Maxes[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.063, -0.938,  0.45 ],\n",
       "        [ 0.25 , -0.813,  0.563],\n",
       "        [ 0.188, -0.375,  0.875],\n",
       "        [ 0.25 , -0.75 ,  0.375],\n",
       "        [ 0.125, -0.875,  0.563]]),\n",
       " array([[ 0.438, -0.063,  0.875],\n",
       "        [ 0.438, -0.063,  0.938],\n",
       "        [ 0.438,  0.   ,  0.813],\n",
       "        [ 0.438,  0.   ,  0.938],\n",
       "        [ 0.438,  0.   ,  0.875]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Maax= Values.reshape((Unique_Time,freq,3)).max(axis=1)\n",
    "Maax[0:5], Maax[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([-0.1  , -1.375, -0.038]),\n",
       "  array([-0.125, -1.375,  0.   ]),\n",
       "  array([-0.438, -1.375, -0.125]),\n",
       "  array([-0.125, -1.438, -0.125]),\n",
       "  array([-0.125, -1.375,  0.   ])],\n",
       " [array([ 0.313, -0.125,  0.625]),\n",
       "  array([ 0.313, -0.125,  0.813]),\n",
       "  array([ 0.375, -0.063,  0.813]),\n",
       "  array([ 0.313, -0.125,  0.875]),\n",
       "  array([ 0.375, -0.063,  0.813])])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mins[0:5],Mins[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.1  , -1.375, -0.038],\n",
       "        [-0.125, -1.375,  0.   ],\n",
       "        [-0.438, -1.375, -0.125],\n",
       "        [-0.125, -1.438, -0.125],\n",
       "        [-0.125, -1.375,  0.   ]]),\n",
       " array([[ 0.313, -0.125,  0.625],\n",
       "        [ 0.313, -0.125,  0.813],\n",
       "        [ 0.375, -0.063,  0.813],\n",
       "        [ 0.313, -0.125,  0.875],\n",
       "        [ 0.375, -0.063,  0.813]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Miin= np.min(Values.reshape((Unique_Time,freq,3)),axis=1)\n",
    "Miin[0:5], Miin[-5::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.   , -0.938,  0.063],\n",
       "       [ 0.05 , -0.988,  0.013],\n",
       "       [ 0.063, -0.963, -0.038],\n",
       "       ...,\n",
       "       [ 0.438,  0.   ,  0.813],\n",
       "       [ 0.438,  0.   ,  0.813],\n",
       "       [ 0.438,  0.   ,  0.813]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2021-05-14 16:15:24.000\n",
       "10        2021-05-14 16:15:25.000\n",
       "20        2021-05-14 16:15:26.000\n",
       "30        2021-05-14 16:15:27.000\n",
       "40        2021-05-14 16:15:28.000\n",
       "                    ...          \n",
       "8403210   2021-05-24 09:40:48.400\n",
       "8403220   2021-05-24 09:40:49.400\n",
       "8403230   2021-05-24 09:40:50.400\n",
       "8403240   2021-05-24 09:40:51.400\n",
       "8403250   2021-05-24 09:40:52.400\n",
       "Name: Timestamp, Length: 840326, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorize features\n",
    "#pd.to_datetime(Data.loc[::freq,'Timestamp'],format=\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "#Norm.reshape((Unique_Time,freq)).std(axis=1)\n",
    "#Values.reshape((Unique_Time,freq,3)).mean(axis=1)\n",
    "#Values.reshape((Unique_Time,freq,3)).max(axis=1)\n",
    "#Values.reshape((Unique_Time,freq,3)).min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "MainPath = '/media/amlan/Data/Thesis Data/Raw Data/ZU_2021_1/COLLAR/GPS/'\n",
    "os.makedirs(SavePath, exist_ok=True)  \n",
    "paths = os.listdir(MainPath)\n",
    "paths = [i for i in paths if 'DS_Store' not in i]\n",
    "y = paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File:  ZU_VZUF051_RRTB_Axy010_20210516-20210524\n",
      "Dimensions:  (8403291, 4)\n",
      "                 Timestamp      X      Y      Z\n",
      "0  14/05/2021 16:15:24.000 -1.000 -0.438 -0.125\n",
      "1  14/05/2021 16:15:24.100 -0.888 -0.550 -0.013\n",
      "2  14/05/2021 16:15:24.200 -0.925 -0.563  0.000\n",
      "3  14/05/2021 16:15:24.300 -0.894 -0.563  0.044\n",
      "4  14/05/2021 16:15:24.400 -0.875 -0.563  0.025\n",
      "                 Timestamp      X      Y      Z\n",
      "0  14/05/2021 16:15:24.000 -1.000 -0.438 -0.125\n",
      "1  14/05/2021 16:15:24.100 -0.888 -0.550 -0.013\n",
      "2  14/05/2021 16:15:24.200 -0.925 -0.563  0.000\n",
      "3  14/05/2021 16:15:24.300 -0.894 -0.563  0.044\n",
      "4  14/05/2021 16:15:24.400 -0.875 -0.563  0.025\n"
     ]
    }
   ],
   "source": [
    "def clean_leading_zeros(df):\n",
    "    \n",
    "    if pd.to_datetime(df.loc[1,'Timestamp']) - pd.to_datetime(df.loc[0,'Timestamp']) >= pd.Timedelta(1, \"s\") :\n",
    "        Leading_Zeros = df.loc[~(df.drop(['Timestamp'],axis=1)==0).all(axis=1)].index[0]\n",
    "        print('There are leading zeros till ',Leading_Zeros)\n",
    "        return df.loc[Leading_Zeros::,:]\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "y = paths[0]\n",
    "freq = 10\n",
    "File = str(y) + '/' + str(y) + '.csv' \n",
    "Data = pd.read_csv(MainPath + File,usecols = ['Timestamp','X','Y','Z']) \n",
    "print('\\nFile: ', y)\n",
    "print('Dimensions: ',Data.shape)\n",
    "print(Data.head())\n",
    "\n",
    "Data = clean_leading_zeros(Data)\n",
    "print(Data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
